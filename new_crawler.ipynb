{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# pandas 모듈은 흔히 pd라는 약칭으로 사용된다. Global 표준에 가깝다.\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "# 커스텀 라이브러리를 import한다.\n",
    "from pbp_plot import *\n",
    "from misc import *\n",
    "\n",
    "# precision 세팅을 한다. 내부 값은 소수점 5자리까지 표시되도록 저장하고, display 시에는 1자리로 표시하도록 한다.\n",
    "pd.set_option('precision', 5)\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "\n",
    "set_fonts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import regex\n",
    "from bs4 import BeautifulSoup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pbp_download import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`JSON` 파일은 모바일 페이지에서 긁어온 정보를 취사선택, 취합한 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pbp_download(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_relay(args, lm=None):\n",
    "    # return True or False\n",
    "    relay_url = 'http://m.sports.naver.com/ajax/baseball/gamecenter/kbo/relayText.nhn'\n",
    "    record_url = 'http://m.sports.naver.com/ajax/baseball/gamecenter/kbo/record.nhn'\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    today_year = now.year\n",
    "    today_date = int(now.date().strftime('%m%d'))\n",
    "    \n",
    "    game_ids = get_game_ids(args)\n",
    "    if (game_ids is None) or (len(game_ids) == 0):\n",
    "        print('no game ids')\n",
    "        print('args: {}'.format(args))\n",
    "        if lm is not None:\n",
    "            lm.log('no game ids')\n",
    "            lm.log('args: {}'.format(args))\n",
    "        return False\n",
    "\n",
    "    if lm is not None:\n",
    "        lm.resetLogHandler()\n",
    "        lm.setLogPath(os.getcwd())\n",
    "        lm.setLogFileName('relay_download_log.txt')\n",
    "        lm.cleanLog()\n",
    "        lm.createLogHandler()\n",
    "        lm.log('---- Relay Text Download Log ----')\n",
    "\n",
    "    if not os.path.isdir('pbp_data'):\n",
    "        os.mkdir('pbp_data')\n",
    "    os.chdir('pbp_data')\n",
    "    # path: pbp_data\n",
    "\n",
    "    print(\"##################################################\")\n",
    "    print(\"######        DOWNLOAD RELAY DATA          #######\")\n",
    "    print(\"##################################################\")\n",
    "\n",
    "    for year in game_ids.keys():\n",
    "        start1 = time.time()\n",
    "        print(\" Year {}\".format(year))\n",
    "        if len(game_ids[year]) == 0:\n",
    "            print('month id is empty')\n",
    "            print('args: {}'.format(args))\n",
    "            if lm is not None:\n",
    "                lm.log('month id is empty')\n",
    "                lm.log('args : {}'.format(args))\n",
    "            os.chdir('../..')\n",
    "            return False\n",
    "\n",
    "        if not os.path.isdir(str(year)):\n",
    "            os.mkdir(str(year))\n",
    "        os.chdir(str(year))\n",
    "        # path: pbp_data/year\n",
    "\n",
    "        for month in game_ids[year].keys():\n",
    "            start2 = time.time()\n",
    "            print(\"  Month {}\".format(month))\n",
    "            if len(game_ids[year][month]) == 0:\n",
    "                print('month id is empty')\n",
    "                print('args: {}'.format(args))\n",
    "                if lm is not None:\n",
    "                    lm.log('month id is empty')\n",
    "                    lm.log('args : {}'.format(args))\n",
    "                os.chdir('../..')\n",
    "                return False\n",
    "\n",
    "            if not os.path.isdir(str(month)):\n",
    "                os.mkdir(str(month))\n",
    "            os.chdir(str(month))\n",
    "            # path: pbp_data/year/month\n",
    "\n",
    "            # download\n",
    "            done = 0\n",
    "            skipped = 0\n",
    "            for game_id in game_ids[year][month]:\n",
    "                game_id_year = int(game_id[:4])\n",
    "                game_id_date = int(game_id[4:8])\n",
    "                game_id_team = game_id[8:10]\n",
    "                if (game_id_year < 2008) or (game_id_year > 7777):\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                if (game_id_year == today_year) and (game_id_date > today_date):\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                if game_id_date < int(regular_start[game_id[:4]]):\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                if game_id_date >= int(playoff_start[game_id[:4]]):\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                if game_id_team not in teams:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                if not check_url2(relay_url):\n",
    "                    skipped += 1\n",
    "                    if lm is not None:\n",
    "                        lm.log('URL error : {}'.format(relay_url))\n",
    "                    continue\n",
    "\n",
    "                relay_text_output_file = game_id + '_relay.csv'\n",
    "                relay_batting_lineup_file = game_id + '_batting.csv'\n",
    "                relay_pitching_lineup_file = game_id + '_pitching.csv'\n",
    "                if (int(game_id[:4]) == today_year) &\\\n",
    "                   (int(game_id[4:6]) == now.month) &\\\n",
    "                   (int(game_id[6:8]) == now.day):\n",
    "                       done = done\n",
    "                elif (os.path.isfile(relay_text_output_file)) and \\\n",
    "                        (os.path.getsize(relay_text_output_file) > 0):\n",
    "                    done += 1\n",
    "                    if lm is not None:\n",
    "                        lm.log('File Duplicate : {}'.format(game_id))\n",
    "                    continue\n",
    "\n",
    "                params = {\n",
    "                    'gameId': game_id,\n",
    "                    'half': '1'\n",
    "                }\n",
    "\n",
    "                headers = {\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "                                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                                  'Chrome/59.0.3071.115 Safari/537.36',\n",
    "                    'X-Requested-With': 'XMLHttpRequest',\n",
    "                    'Host': 'm.sports.naver.com',\n",
    "                    'Referer': 'http://m.sports.naver.com/baseball/gamecenter/kbo/index.nhn?&gameId='\n",
    "                               + game_id\n",
    "                               + '&tab=relay'\n",
    "                }\n",
    "\n",
    "                response = requests.get(relay_url, params=params, headers=headers)\n",
    "\n",
    "                if (response is not None) & (response.status_code >= 400):\n",
    "                    txt = {}\n",
    "                    js = response.json()\n",
    "                    if isinstance(js, str):\n",
    "                        js = json.loads(js)\n",
    "                    last_inning = js['currentInning']\n",
    "\n",
    "                    if last_inning is None:\n",
    "                        skipped += 1\n",
    "                        lm.log('Gameday not found : {}'.format(game_id))\n",
    "                        continue\n",
    "\n",
    "                    txt['relayList'] = {}\n",
    "                    for i in range(len(js['relayList'])):\n",
    "                        text_index = js['relayList'][i]['no']\n",
    "                        txt['relayList'][text_index] = js['relayList'][i]\n",
    "                        texts = txt['relayList'][text_index]['textOptionList']\n",
    "                        for i in range(len(texts)):\n",
    "                            texts[i]['text'].encode('cp949', 'ignore')\n",
    "                    txt['homeTeamLineUp'] = js['homeTeamLineUp']\n",
    "                    txt['awayTeamLineUp'] = js['awayTeamLineUp']\n",
    "\n",
    "                    txt['stadium'] = js['schedule']['stadium']\n",
    "\n",
    "                    response.close()\n",
    "\n",
    "                    for inn in range(2, last_inning + 1):\n",
    "                        params = {\n",
    "                            'gameId': game_id,\n",
    "                            'half': str(inn)\n",
    "                        }\n",
    "\n",
    "                        response = requests.get(relay_url, params=params, headers=headers)\n",
    "                        if response is not None:\n",
    "                            js = response.json()\n",
    "                            if isinstance(js, str):\n",
    "                                js = json.loads(js)\n",
    "                            for i in range(len(js['relayList'])):\n",
    "                                txt['relayList'][js['relayList'][i]['no']] = js['relayList'][i]\n",
    "                                texts = txt['relayList'][js['relayList'][i]['no']]['textOptionList']\n",
    "                                for i in range(len(texts)):\n",
    "                                    texts[i]['text'].encode('cp949', 'ignore')\n",
    "                        else:\n",
    "                            skipped += 1\n",
    "                            if lm is not None:\n",
    "                                lm.log('Cannot get response : {}'.format(game_id))\n",
    "\n",
    "                        response.close()\n",
    "\n",
    "                    # get referee\n",
    "                    params = {\n",
    "                        'gameId': game_id\n",
    "                    }\n",
    "\n",
    "                    headers = {\n",
    "                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, '\n",
    "                                      'like Gecko) Chrome/59.0.3071.115 Safari/537.36',\n",
    "                        'X-Requested-With': 'XMLHttpRequest',\n",
    "                        'Host': 'm.sports.naver.com',\n",
    "                        'Referer': 'http://m.sports.naver.com/baseball/gamecenter/kbo/index.nhn?gameId='\n",
    "                                   + game_id\n",
    "                                   + '&tab=record'\n",
    "                    }\n",
    "\n",
    "                    response = requests.get(record_url, params=params, headers=headers)\n",
    "\n",
    "                    p = regex.compile('(?<=\\\"etcRecords\\\":\\[)[\\\\\\.\\{\\}\\\"0-9:\\s\\(\\)\\,\\ba-z가-힣\\{\\}]+')\n",
    "                    result = p.findall(response.text)\n",
    "                    if len(result) == 0:\n",
    "                        txt['referee'] = ''\n",
    "                    else:\n",
    "                        txt['referee'] = result[0].split('{')[-1].split('\":\"')[1].split(' ')[0]\n",
    "\n",
    "                    response.close()\n",
    "                    \n",
    "                    \n",
    "                    ### 필요한 내용 담아서 저장 ###\n",
    "                    rl = txt['relayList']\n",
    "\n",
    "                    tl_keys = []\n",
    "                    rl_keys = []\n",
    "                    pts_keys = []\n",
    "                    for k in rl.keys():\n",
    "                        keys = rl.get(k).keys()\n",
    "                        for key in keys:\n",
    "                            if key in rl_keys:\n",
    "                                continue\n",
    "                            else:\n",
    "                                rl_keys.append(key)\n",
    "\n",
    "                        for j in range(len(rl.get(k).get('textOptionList'))):\n",
    "                            keys = rl.get(k).get('textOptionList')[j].keys()\n",
    "                            for key in keys:\n",
    "                                if key in tl_keys:\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    tl_keys.append(key)\n",
    "                        for j in range(len(rl.get(k).get('ptsOptionList'))):\n",
    "                            keys = rl.get(k).get('ptsOptionList')[j].keys()\n",
    "                            for key in keys:\n",
    "                                if key in pts_keys:\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    pts_keys.append(key)\n",
    "\n",
    "                    tl_keys_copy = tl_keys.copy()\n",
    "                    if 'currentGameState' in tl_keys:\n",
    "                        tl_keys_copy.remove('currentGameState')\n",
    "                    if 'batterRecord' in tl_keys:\n",
    "                        tl_keys_copy.remove('batterRecord')\n",
    "                    if 'pitcherResult' in tl_keys:\n",
    "                        tl_keys_copy.remove('pitcherResult')\n",
    "                    if 'pitchResult' in tl_keys:\n",
    "                        tl_keys_copy.remove('pitchResult')\n",
    "                    if 'pitchNum' in tl_keys:\n",
    "                        tl_keys_copy.remove('pitchNum')\n",
    "\n",
    "                    ts_set = []\n",
    "                    referee = txt['referee']\n",
    "                    stadium = txt['stadium']\n",
    "                    for k in rl.keys():\n",
    "                        for j in range(len(rl.get(k).get('textOptionList'))):\n",
    "                            ts = rl.get(k).get('textOptionList')[j]\n",
    "\n",
    "                            ts_dict = {}\n",
    "                            ts_dict['textOrder'] = int(k)\n",
    "                            for key in tl_keys_copy:\n",
    "                                if key == 'playerChange':\n",
    "                                    if ts.get(key) is not None:\n",
    "                                        for x in ['outPlayer', 'inPlayer', 'shiftPlayer']:\n",
    "                                            if x in ts.get(key).keys():\n",
    "                                                ts_dict[x] = ts.get(key).get(x).get('playerId')\n",
    "\n",
    "                                else:\n",
    "                                    ts_dict[key] = None if key not in ts.keys() else ts.get(key)\n",
    "                            ts_dict['referee'] = referee\n",
    "                            ts_dict['stadium'] = stadium\n",
    "                            ts_set.append(ts_dict)\n",
    "                    if 'playerChange' in tl_keys:\n",
    "                        tl_keys_copy.remove('playerChange')\n",
    "                    ts_df = pd.DataFrame(ts_set)\n",
    "                    ts_df = ts_df.rename(index=str, columns={'ptsPitchId': 'pitchId'})\n",
    "\n",
    "                    pdata_set = []\n",
    "                    if len(pts_keys) > 0:\n",
    "                        for k in rl.keys():\n",
    "                            for j in range(len(rl.get(k).get('ptsOptionList'))):\n",
    "                                pdata = rl.get(k).get('ptsOptionList')[j]\n",
    "\n",
    "                                pdata_dict = {}\n",
    "                                pdata_dict['textOrder'] = int(k)\n",
    "                                for key in pts_keys:\n",
    "                                    pdata_dict[key] = None if key not in pdata.keys() else pdata.get(key)\n",
    "                                pdata_dict.pop('crossPlateY')\n",
    "                                pdata_dict.pop('y0')\n",
    "                                pdata_dict.pop('inn')\n",
    "                                pdata_dict.pop('ballcount')\n",
    "                                pdata_set.append(pdata_dict)\n",
    "\n",
    "                        pdata_df = pd.DataFrame(pdata_set)\n",
    "                        pdata_df.head()\n",
    "                    else:\n",
    "                        pdata_df = None\n",
    "\n",
    "                    if pdata_df is not None:\n",
    "                        merge_df = pd.merge(ts_df, pdata_df, how='outer').sort_values(['textOrder', 'seqno'])\n",
    "                    else:\n",
    "                        merge_df = ts_df.sort_values(['textOrder', 'seqno'])\n",
    "\n",
    "                    ######################\n",
    "                    ### 라인업 다운로드 ###\n",
    "                    ######################\n",
    "                    lineup_url = 'https://sports.news.naver.com/gameCenter/gameRecord.nhn?category=kbo&gameId='\n",
    "                    lurl = lineup_url + game_id\n",
    "                    lreq = requests.get(lurl)\n",
    "                    lsoup = BeautifulSoup(lreq.text, 'lxml')\n",
    "                    lreq.close()\n",
    "\n",
    "                    scripts = lsoup.find_all('script')\n",
    "                    team_names = lsoup.find_all('span', attrs={'class': 't_name_txt'})\n",
    "                    away_team_name = team_names[0].contents[0].split(' ')[0]\n",
    "                    home_team_name = team_names[1].contents[0].split(' ')[0]\n",
    "                    contents = None\n",
    "\n",
    "                    for tag in scripts:\n",
    "                        if len(tag.contents) > 0:\n",
    "                            if tag.contents[0].find('DataClass = ') > 0:\n",
    "                                contents = tag.contents[0]\n",
    "                                start = contents.find('DataClass = ') + 36\n",
    "                                end = contents.find('_homeTeam')\n",
    "                                try:\n",
    "                                    oldjs = contents[start:end].strip()\n",
    "                                    while oldjs[-1] != '}':\n",
    "                                        oldjs = oldjs[:-1]\n",
    "                                    while oldjs[0] != '{':\n",
    "                                        oldjs = oldjs[1:]\n",
    "                                    cont = json.loads(oldjs)\n",
    "                                    break\n",
    "                                except Exception as e:\n",
    "                                    os.chdir('../../..')\n",
    "                                    print()\n",
    "                                    print(game_id)\n",
    "                                    print(oldjs)\n",
    "                                    print(e)\n",
    "                                    return\n",
    "                    \n",
    "                    bbs = cont.get('battersBoxscore')\n",
    "                    al = bbs.get('away')\n",
    "                    hl = bbs.get('home')\n",
    "\n",
    "                    pos_dict = {'중': '중견수', '좌': '좌익수', '우': '우익수', '유': '유격수', '포': '포수', '지': '지명타자',\n",
    "                                '一': '1루수', '二': '2루수', '三': '3루수'}\n",
    "\n",
    "                    posnum_dict = {'중': 8, '좌': 7, '우': 9, '유': 6, '포': 2, '지': 0,\n",
    "                                '一': 3, '二': 4, '三': 5}\n",
    "                    homes = []\n",
    "                    aways = []\n",
    "                    for i in range(len(hl)):\n",
    "                        player = hl[i]\n",
    "                        name = player.get('name')\n",
    "                        pos = player.get('pos')[0]\n",
    "                        homes.append({'name': name, 'pos': pos})\n",
    "\n",
    "                    for i in range(len(al)):\n",
    "                        player = al[i]\n",
    "                        name = player.get('name')\n",
    "                        pos = player.get('pos')[0]\n",
    "                        aways.append({'name': name, 'pos': pos})\n",
    "\n",
    "                    ### 라인업 가져다와서 더하기 ###\n",
    "                    hit_columns = ['name', 'pCode', 'posName', 'pos',\n",
    "                                'hitType', 'seqno', 'batOrder',\n",
    "                                'ab', 'hit', 'run', 'rbi',\n",
    "                                'hr', 'bb', 'so']\n",
    "                    pit_columns = ['name', 'pCode', 'hitType', 'seqno',\n",
    "                                'inn', 'run', 'er', 'hit', 'hr',\n",
    "                                'bb', 'kk', 'hbp', 'wp', 'ballCount']\n",
    "                    \n",
    "                    atl = txt.get('awayTeamLineUp')\n",
    "                    abat = atl.get('batter')\n",
    "                    apit = atl.get('pitcher')\n",
    "                    abats = pd.DataFrame(abat, columns=hit_columns).sort_values(['batOrder', 'seqno'])\n",
    "                    apits = pd.DataFrame(apit, columns=pit_columns).sort_values('seqno')\n",
    "\n",
    "                    htl = txt.get('homeTeamLineUp')\n",
    "                    hbat = htl.get('batter')\n",
    "                    hpit = htl.get('pitcher')\n",
    "                    hbats = pd.DataFrame(hbat, columns=hit_columns).sort_values(['batOrder', 'seqno'])\n",
    "                    hpits = pd.DataFrame(hpit, columns=pit_columns).sort_values('seqno')\n",
    "\n",
    "                    for a in aways:\n",
    "                        if a.get('pos') == '교':\n",
    "                            continue\n",
    "                        abats.loc[abats.name == a.get('name'), 'posName'] = pos_dict.get(a.get('pos'))\n",
    "                        abats.loc[abats.name == a.get('name'), 'pos'] = posnum_dict.get(a.get('pos'))\n",
    "                    \n",
    "                    for h in homes:\n",
    "                        if h.get('pos') == '교':\n",
    "                            continue\n",
    "                        hbats.loc[hbats.name == h.get('name'), 'posName'] = pos_dict.get(h.get('pos'))\n",
    "                        hbats.loc[hbats.name == h.get('name'), 'pos'] = posnum_dict.get(h.get('pos'))\n",
    "                    abats['homeaway'] = 'a'\n",
    "                    hbats['homeaway'] = 'h'\n",
    "                    apits['homeaway'] = 'a'\n",
    "                    hpits['homeaway'] = 'h'\n",
    "                    abats['team_name'] = away_team_name\n",
    "                    hbats['team_name'] = home_team_name\n",
    "                    apits['team_name'] = away_team_name\n",
    "                    hpits['team_name'] = home_team_name\n",
    "\n",
    "                    bats = pd.concat([abats, hbats])\n",
    "                    pits = pd.concat([apits, hpits])\n",
    "\n",
    "                    ### 저장\n",
    "                    if sys.platform == 'win32':\n",
    "                        bats.to_csv(relay_batting_lineup_file, index=False, encoding='cp949')\n",
    "                        pits.to_csv(relay_pitching_lineup_file, index=False, encoding='cp949')\n",
    "                        merge_df.to_csv(relay_text_output_file, index=False, encoding='cp949')\n",
    "                    else:\n",
    "                        bats.to_csv(relay_batting_lineup_file, index=False)\n",
    "                        pits.to_csv(relay_pitching_lineup_file, index=False)\n",
    "                        merge_df.to_csv(relay_text_output_file, index=False)\n",
    "\n",
    "                    done += 1\n",
    "                else:\n",
    "                    skipped += 1\n",
    "                    if lm is not None:\n",
    "                        lm.log('Cannot get response : {}'.format(game_id))\n",
    "\n",
    "                print_progress('    Downloading: ', len(game_ids[year][month]), done, skipped)\n",
    "\n",
    "            # download done\n",
    "            print_progress('    Downloading: ', len(game_ids[year][month]), done, skipped)\n",
    "            print('\\n        Downloaded {} files'.format(done))\n",
    "            print('        (Skipped {} files)'.format(skipped))\n",
    "            end2 = time.time()\n",
    "            print('            -- elapsed {:.3f} sec for month {}'.format(end2 - start2, month))\n",
    "\n",
    "            os.chdir('..')\n",
    "            # path: pbp_data/year\n",
    "        end1 = time.time()\n",
    "        print('   -- elapsed {:.3f} sec for year {}'.format(end1 - start1, year))\n",
    "        # months done\n",
    "        os.chdir('..')\n",
    "        # path: pbp_data/\n",
    "    # years done\n",
    "    os.chdir('..')\n",
    "    # path: root\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpark/work/KBO_pbp_text_crawler\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: pbp_data/2019/3/*relay.csv: No such file or directory\n",
      "rm: pbp_data/2019/4/*relay.csv: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm pbp_data/2019/3/*relay.csv pbp_data/2019/4/*relay.csv\n",
    "!rm pbp_data/2019/3/*batting.csv pbp_data/2019/4/*batting.csv\n",
    "!rm pbp_data/2019/3/*pitching.csv pbp_data/2019/4/*pitching.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 94200\n",
      "-rw-r--r--    1 kpark  staff   835551  2 24 17:06 20190323HHOB02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    22224  2 24 17:06 20190323HHOB02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35863  2 24 17:06 20190323HHOB02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   847841  2 24 17:06 20190323KTSK02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    22201  2 24 17:06 20190323KTSK02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35996  2 24 17:06 20190323KTSK02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   771075  2 24 17:06 20190323LGHT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    20444  2 24 17:06 20190323LGHT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    33435  2 24 17:06 20190323LGHT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   764633  2 24 17:06 20190323SSNC02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    20274  2 24 17:06 20190323SSNC02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    32664  2 24 17:06 20190323SSNC02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   890200  2 24 17:06 20190323WOLT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    23791  2 24 17:06 20190323WOLT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35780  2 24 17:06 20190323WOLT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   832387  2 24 17:06 20190324HHOB02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    22131  2 24 17:06 20190324HHOB02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    33983  2 24 17:06 20190324HHOB02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   870258  2 24 17:06 20190324KTSK02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    22868  2 24 17:06 20190324KTSK02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    36938  2 24 17:06 20190324KTSK02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   895094  2 24 17:06 20190324LGHT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    23824  2 24 17:06 20190324LGHT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    38012  2 24 17:06 20190324LGHT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   885026  2 24 17:06 20190324SSNC02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    23767  2 24 17:06 20190324SSNC02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    37055  2 24 17:06 20190324SSNC02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   830264  2 24 17:06 20190324WOLT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    21576  2 24 17:06 20190324WOLT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    36306  2 24 17:06 20190324WOLT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff  1019047  2 24 17:06 20190326HHHT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    27279  2 24 17:06 20190326HHHT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    41538  2 24 17:06 20190326HHHT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff  1201333  2 24 17:06 20190326KTNC02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    32103  2 24 17:06 20190326KTNC02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    50971  2 24 17:06 20190326KTNC02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   804231  2 24 17:06 20190326LGSK02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    20853  2 24 17:06 20190326LGSK02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    34189  2 24 17:06 20190326LGSK02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   835317  2 24 17:06 20190326SSLT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    22051  2 24 17:06 20190326SSLT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35887  2 24 17:06 20190326SSLT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   921652  2 24 17:06 20190326WOOB02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    23568  2 24 17:06 20190326WOOB02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    42538  2 24 17:06 20190326WOOB02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   965602  2 24 17:06 20190327HHHT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    25346  2 24 17:06 20190327HHHT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    41156  2 24 17:06 20190327HHHT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   700648  2 24 17:06 20190327KTNC02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    18446  2 24 17:06 20190327KTNC02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    28483  2 24 17:06 20190327KTNC02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   966204  2 24 17:06 20190327LGSK02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    25011  2 24 17:06 20190327LGSK02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    40742  2 24 17:06 20190327LGSK02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff  1171914  2 24 17:06 20190327SSLT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    31301  2 24 17:06 20190327SSLT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    49230  2 24 17:06 20190327SSLT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   859610  2 24 17:06 20190327WOOB02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    23436  2 24 17:06 20190327WOOB02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35563  2 24 17:06 20190327WOOB02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   830992  2 24 17:06 20190328HHHT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    21795  2 24 17:06 20190328HHHT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35831  2 24 17:06 20190328HHHT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   855476  2 24 17:06 20190328KTNC02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    22861  2 24 17:06 20190328KTNC02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35510  2 24 17:06 20190328KTNC02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   691288  2 24 17:06 20190328LGSK02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    17674  2 24 17:06 20190328LGSK02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    30018  2 24 17:06 20190328LGSK02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff  1098758  2 24 17:06 20190328SSLT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    29738  2 24 17:06 20190328SSLT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    46626  2 24 17:06 20190328SSLT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   869263  2 24 17:06 20190328WOOB02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    23035  2 24 17:06 20190328WOOB02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    37905  2 24 17:06 20190328WOOB02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   783255  2 24 17:06 20190329HTKT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    20742  2 24 17:06 20190329HTKT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    31898  2 24 17:06 20190329HTKT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   783984  2 24 17:06 20190329LTLG02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    20309  2 24 17:06 20190329LTLG02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    33398  2 24 17:06 20190329LTLG02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   851457  2 24 17:06 20190329NCHH02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    22966  2 24 17:06 20190329NCHH02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35663  2 24 17:06 20190329NCHH02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   893719  2 24 17:06 20190329OBSS02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    23884  2 24 17:06 20190329OBSS02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    38692  2 24 17:06 20190329OBSS02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   858926  2 24 17:06 20190329SKWO02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    22754  2 24 17:06 20190329SKWO02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    36386  2 24 17:06 20190329SKWO02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   904283  2 24 17:06 20190330HTKT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    23835  2 24 17:06 20190330HTKT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    38319  2 24 17:06 20190330HTKT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   865198  2 24 17:06 20190330LTLG02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    22886  2 24 17:06 20190330LTLG02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35515  2 24 17:06 20190330LTLG02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   968892  2 24 17:06 20190330NCHH02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    26281  2 24 17:06 20190330NCHH02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    38414  2 24 17:06 20190330NCHH02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   735905  2 24 17:06 20190330OBSS02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    19326  2 24 17:06 20190330OBSS02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    30020  2 24 17:06 20190330OBSS02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   807815  2 24 17:06 20190330SKWO02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    21059  2 24 17:06 20190330SKWO02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    35168  2 24 17:06 20190330SKWO02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   960423  2 24 17:07 20190331HTKT02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    25408  2 24 17:07 20190331HTKT02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    40947  2 24 17:07 20190331HTKT02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   971469  2 24 17:07 20190331LTLG02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    25916  2 24 17:07 20190331LTLG02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    39117  2 24 17:07 20190331LTLG02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   906683  2 24 17:07 20190331NCHH02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    24015  2 24 17:07 20190331NCHH02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    39741  2 24 17:07 20190331NCHH02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff   986815  2 24 17:07 20190331OBSS02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    25561  2 24 17:07 20190331OBSS02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    44181  2 24 17:07 20190331OBSS02019_ptsset.csv\n",
      "-rw-r--r--    1 kpark  staff  1013725  2 24 17:07 20190331SKWO02019_relay.json\n",
      "-rw-r--r--    1 kpark  staff    26920  2 24 17:07 20190331SKWO02019_textset.csv\n",
      "-rw-r--r--    1 kpark  staff    42702  2 24 17:07 20190331SKWO02019_ptsset.csv\n",
      "drwxr-xr-x   11 kpark  staff      352  2 24 17:25 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "-rw-r--r--    1 kpark  staff   109735  2 24 17:25 20190323HHOB0.csv\n",
      "-rw-r--r--    1 kpark  staff   109486  2 24 17:25 20190323KTSK0.csv\n",
      "-rw-r--r--    1 kpark  staff   101060  2 24 17:25 20190323LGHT0.csv\n",
      "-rw-r--r--    1 kpark  staff   101620  2 24 17:25 20190323SSNC0.csv\n",
      "-rw-r--r--    1 kpark  staff   109337  2 24 17:25 20190323WOLT0.csv\n",
      "-rw-r--r--    1 kpark  staff   102052  2 24 17:25 20190324HHOB0.csv\n",
      "-rw-r--r--    1 kpark  staff   112033  2 24 17:25 20190324KTSK0.csv\n",
      "-rw-r--r--    1 kpark  staff   114995  2 24 17:25 20190324LGHT0.csv\n",
      "-rw-r--r--    1 kpark  staff   112871  2 24 17:25 20190324SSNC0.csv\n",
      "-rw-r--r--    1 kpark  staff   109877  2 24 17:25 20190324WOLT0.csv\n",
      "-rw-r--r--    1 kpark  staff   126445  2 24 17:25 20190326HHHT0.csv\n",
      "-rw-r--r--    1 kpark  staff   154158  2 24 17:25 20190326KTNC0.csv\n",
      "-rw-r--r--    1 kpark  staff   101353  2 24 17:25 20190326LGSK0.csv\n",
      "-rw-r--r--    1 kpark  staff   108507  2 24 17:25 20190326SSLT0.csv\n",
      "-rw-r--r--    1 kpark  staff   126733  2 24 17:25 20190326WOOB0.csv\n",
      "-rw-r--r--    1 kpark  staff   125990  2 24 17:25 20190327HHHT0.csv\n",
      "-rw-r--r--    1 kpark  staff    86516  2 24 17:25 20190327KTNC0.csv\n",
      "-rw-r--r--    1 kpark  staff   120260  2 24 17:25 20190327LGSK0.csv\n",
      "-rw-r--r--    1 kpark  staff   149084  2 24 17:25 20190327SSLT0.csv\n",
      "-rw-r--r--    1 kpark  staff   107710  2 24 17:25 20190327WOOB0.csv\n",
      "-rw-r--r--    1 kpark  staff   108325  2 24 17:25 20190328HHHT0.csv\n",
      "-rw-r--r--    1 kpark  staff   106740  2 24 17:25 20190328KTNC0.csv\n",
      "-rw-r--r--    1 kpark  staff    89110  2 24 17:25 20190328LGSK0.csv\n",
      "-rw-r--r--    1 kpark  staff   142746  2 24 17:25 20190328SSLT0.csv\n",
      "-rw-r--r--    1 kpark  staff   113068  2 24 17:25 20190328WOOB0.csv\n",
      "-rw-r--r--    1 kpark  staff    98894  2 24 17:25 20190329HTKT0.csv\n",
      "-rw-r--r--    1 kpark  staff   101028  2 24 17:25 20190329LTLG0.csv\n",
      "-rw-r--r--    1 kpark  staff   105848  2 24 17:25 20190329NCHH0.csv\n",
      "-rw-r--r--    1 kpark  staff   120164  2 24 17:25 20190329OBSS0.csv\n",
      "-rw-r--r--    1 kpark  staff   108709  2 24 17:25 20190329SKWO0.csv\n",
      "-rw-r--r--    1 kpark  staff   118038  2 24 17:25 20190330HTKT0.csv\n",
      "-rw-r--r--    1 kpark  staff   107203  2 24 17:25 20190330LTLG0.csv\n",
      "-rw-r--r--    1 kpark  staff   119268  2 24 17:25 20190330NCHH0.csv\n",
      "-rw-r--r--    1 kpark  staff    93964  2 24 17:25 20190330OBSS0.csv\n",
      "-rw-r--r--    1 kpark  staff   107179  2 24 17:25 20190330SKWO0.csv\n",
      "-rw-r--r--    1 kpark  staff   125934  2 24 17:25 20190331HTKT0.csv\n",
      "-rw-r--r--    1 kpark  staff   118243  2 24 17:25 20190331LTLG0.csv\n",
      "-rw-r--r--    1 kpark  staff   118689  2 24 17:25 20190331NCHH0.csv\n",
      "-rw-r--r--    1 kpark  staff   134734  2 24 17:25 20190331OBSS0.csv\n",
      "-rw-r--r--    1 kpark  staff   127965  2 24 17:25 20190331SKWO0.csv\n",
      "-rw-r--r--    1 kpark  staff  4541085  2 24 17:25 2019_3.csv\n",
      "drwxr-xr-x  163 kpark  staff     5216  2 24 17:54 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -altr pbp_data/2019/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [3, 10, 2019, 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable_url = \"https://sports.news.naver.com/kbaseball/schedule/index.nhn?month=\"\n",
    "\n",
    "# parse arguments\n",
    "mon_start = args[0]\n",
    "mon_end = args[1]\n",
    "year_start = args[2]\n",
    "year_end = args[3]\n",
    "\n",
    "# get game ids\n",
    "game_ids = {}\n",
    "\n",
    "for year in range(year_start, year_end + 1):\n",
    "    year_ids = {}\n",
    "\n",
    "    for month in range(mon_start, mon_end + 1):\n",
    "        month_ids = []\n",
    "        timetable = timetable_url + '{}&year={}'.format(str(month), str(year))\n",
    "\n",
    "        response = requests.get(timetable)\n",
    "        table_page = response.text\n",
    "        response.close()\n",
    "        soup = BeautifulSoup(table_page, 'lxml')\n",
    "        buttons = soup.findAll('span', attrs={'class': 'td_btn'})\n",
    "\n",
    "        for btn in buttons:\n",
    "            address = btn.a['href']\n",
    "            game_id = address.split('gameId=')[1]\n",
    "            month_ids.append(game_id)\n",
    "\n",
    "        year_ids[month] = month_ids\n",
    "\n",
    "    game_ids[year] = year_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "######        DOWNLOAD RELAY DATA          #######\n",
      "##################################################\n",
      " Year 2019\n",
      "  Month 3\n",
      "    Downloading: [++++++++++++++++++++++++++++++] 77 / 77, 100.0 %\n",
      "        Downloaded 40 files\n",
      "        (Skipped 37 files)\n",
      "            -- elapsed 56.556 sec for month 3\n",
      "  Month 4\n",
      "    Downloading: [++++++++++++++++++++++++++++++] 113 / 113, 100.0 %\n",
      "        Downloaded 113 files\n",
      "        (Skipped 0 files)\n",
      "            -- elapsed 146.795 sec for month 4\n",
      "  Month 5\n",
      "    Downloading: [++++++++++++++++++++++++++++++] 132 / 132, 100.0 %\n",
      "        Downloaded 132 files\n",
      "        (Skipped 0 files)\n",
      "            -- elapsed 163.439 sec for month 5\n",
      "  Month 6\n",
      "    Downloading: [++++++++++++++++++++++++++++++] 123 / 123, 100.0 %\n",
      "        Downloaded 123 files\n",
      "        (Skipped 0 files)\n",
      "            -- elapsed 144.212 sec for month 6\n",
      "  Month 7\n",
      "    Downloading: [++++++++++++++++++++++++++++++] 92 / 92, 100.0 %\n",
      "        Downloaded 91 files\n",
      "        (Skipped 1 files)\n",
      "            -- elapsed 125.159 sec for month 7\n",
      "  Month 8\n",
      "    Downloading: [++++++++++++++++++++++++++++++] 122 / 122, 100.0 %\n",
      "        Downloaded 122 files\n",
      "        (Skipped 0 files)\n",
      "            -- elapsed 168.086 sec for month 8\n",
      "  Month 9\n",
      "    Downloading: [++++++++++++++++++++++++++++++] 97 / 97, 100.0 %\n",
      "        Downloaded 97 files\n",
      "        (Skipped 0 files)\n",
      "            -- elapsed 140.286 sec for month 9\n",
      "  Month 10\n",
      "    Downloading: [++++++++++++++] 14 / 14, 100.0 %\n",
      "        Downloaded 14 files\n",
      "        (Skipped 0 files)\n",
      "            -- elapsed 29.307 sec for month 10\n",
      "   -- elapsed 973.842 sec for year 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_relay([3, 10, 2019, 2019])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 버그 있던거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'pbp_data/2019/4/20190423HTLG02019_relay.json'\n",
    "f = open(fname, 'r')\n",
    "js = json.load(f)\n",
    "f.close()\n",
    "rl = js.get('relayList')\n",
    "\n",
    "stadium = js.get('stadium')\n",
    "referee = js.get('referee')\n",
    "\n",
    "tl_keys = []\n",
    "rl_keys = []\n",
    "pts_keys = []\n",
    "for k in rl.keys():\n",
    "    keys = rl.get(k).keys()\n",
    "    for key in keys:\n",
    "        if key in rl_keys:\n",
    "            continue\n",
    "        else:\n",
    "            rl_keys.append(key)\n",
    "    \n",
    "    for j in range(len(rl.get(k).get('textOptionList'))):\n",
    "        keys = rl.get(k).get('textOptionList')[j].keys()\n",
    "        for key in keys:\n",
    "            if key in tl_keys:\n",
    "                continue\n",
    "            else:\n",
    "                tl_keys.append(key)\n",
    "    for j in range(len(rl.get(k).get('ptsOptionList'))):\n",
    "        keys = rl.get(k).get('ptsOptionList')[j].keys()\n",
    "        for key in keys:\n",
    "            if key in pts_keys:\n",
    "                continue\n",
    "            else:\n",
    "                pts_keys.append(key)\n",
    "tl_keys_copy = tl_keys.copy()\n",
    "tl_keys_copy.remove('currentGameState')\n",
    "tl_keys_copy.remove('batterRecord')\n",
    "tl_keys_copy.remove('playerChange')\n",
    "tl_keys_copy.remove('pitcherResult')\n",
    "\n",
    "ts_set = []\n",
    "for k in rl.keys():\n",
    "    for j in range(len(rl.get(k).get('textOptionList'))):\n",
    "        ts = rl.get(k).get('textOptionList')[j]\n",
    "        \n",
    "        ts_dict = {}\n",
    "        ts_dict['textOrder'] = int(k)\n",
    "        for key in tl_keys_copy:\n",
    "            ts_dict[key] = None if key not in ts.keys() else ts.get(key)\n",
    "        ts_dict['referee'] = referee\n",
    "        ts_dict['stadium'] = stadium\n",
    "        ts_set.append(ts_dict)\n",
    "ts_df = pd.DataFrame(ts_set)\n",
    "ts_df = ts_df.rename(index=str, columns={'ptsPitchId': 'pitchId'})\n",
    "\n",
    "pdata_set = []\n",
    "if len(pts_keys) > 0:\n",
    "    for k in rl.keys():\n",
    "        for j in range(len(rl.get(k).get('ptsOptionList'))):\n",
    "            pdata = rl.get(k).get('ptsOptionList')[j]\n",
    "\n",
    "            pdata_dict = {}\n",
    "            pdata_dict['textOrder'] = int(k)\n",
    "            for key in pts_keys:\n",
    "                pdata_dict[key] = None if key not in pdata.keys() else pdata.get(key)\n",
    "            pdata_set.append(pdata_dict)\n",
    "        \n",
    "    pdata_df = pd.DataFrame(pdata_set)\n",
    "    pdata_df.head()\n",
    "else:\n",
    "    pdata_df = None\n",
    "\n",
    "if pdata_df is not None:\n",
    "    merge_df = pd.merge(ts_df, pdata_df, how='outer')\n",
    "    # merge_df.to_csv('test.csv', index=False)\n",
    "else:\n",
    "    merge_df = ts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지금은 모바일 페이지 들어가서 이것저것 긁어오는 중.\n",
    "- `relayText.nhn`은 문자중계, 홈라인업, 어웨이라인업, 구장이름(`stadium`)\n",
    "- `record.nhn`은 심판 이름(`referee`)\n",
    "- `request`를 보낼 때 `params`를 파라미터로 같이 보내고, 이 중 `half` 파라미터에 이닝이 들어간다.\n",
    "    - 이 이닝에 나온 문자중계만 `response`로 받음\n",
    "- 리스폰스 객체의 `.json()` 함수로 `JSON` 형태의 데이터를 추출 가능\n",
    "- 안에 `relayList`, `currentInning`, `homeTeamLineUp`, `awayTeamLineUp`, `schedule` 등의 키를 활용\n",
    "    - `relayList`: 문자중계 내역\n",
    "    - `currentInning`: 실시간 현재 이닝 -> 경기 끝난 후에는 경기 마지막 이닝\n",
    "    - `homeTeamLineUp`: 홈팀 라인업\n",
    "    - `awayTeamLineUp`: 어웨이 라인업\n",
    "    - `schedule`: 진행중인 중계 관련 내용이 있는데 여기서 `stadium` 키를 쓰면 구장이 나온다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `relayList`로 얻어온 value는 리스트 형태, 별도의 의미있는 인덱스는 없음(0, 1, ...), 리스트 엘리먼트 각각은 dictionary\n",
    "- `relayList` 딕셔너리 내부에 `no`라는 키가 있는데 경기 문자중계 전체 단위 인덱스(순서)\n",
    "    - 0번이 시작(__1회초 XX 공격__), 마지막 N번이 경기종료 메시지(__승리투수 등 표시__)\n",
    "- 문자중계 내용은 `relayList` 딕셔너리의 `textOptionList` 키로 얻을 수 있는 리스트에 있음\n",
    "- PTS 데이터는 `relayList` 딕셔너리의 `ptsOptionList` 키로 얻을 수 있는 리스트에 있음\n",
    "    - 경우에 따라서 누락된 데이터도 있음\n",
    "    - 순서가 꼭 문자중계와 맞지는 않음\n",
    "    - ptsPitchId 키 값으로 매치해야함\n",
    "- `textOptionList` 리스트 안의 엘리먼트 하나는 또 딕셔너리 object\n",
    "    - 1구1구 단위 메타데이터 포함\n",
    "    - 꼭 필요한(항상 나오는) 요소는...\n",
    "        - `seqno`\n",
    "        - `text`\n",
    "        - `type`\n",
    "        - `stuff` 등등\n",
    "- 지금까지는 json으로 얻어온 object를 JSON 포맷으로 통채로 저장\n",
    "- 앞으로는 object를 dataframe으로 바꾼 다음에 csv 형태로 보기 편하게 바꿔서 저장하는 쪽으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다운로드 과정에서 Unicode 변환 안되는 텍스트는 누락 처리(blank text, '')했음\n",
    "    - `try`, `catch` 써서 `UnicodeEncodeError` 나올 때 별도처리\n",
    "- `.encode` 함수의 `errors` 파라미터를 `ignore`로 설정하면 에러 없이 해결 가능\n",
    "    - 그렇게 바꿈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modify download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [4, 4, 2019, 2019]\n",
    "\n",
    "relay_url = 'http://m.sports.naver.com/ajax/baseball/gamecenter/kbo/relayText.nhn'\n",
    "record_url = 'http://m.sports.naver.com/ajax/baseball/gamecenter/kbo/record.nhn'\n",
    "\n",
    "# game_ids = get_game_ids(args)\n",
    "# game_id = '20180717LGWO02018' ## 유니코드 버그 있는 경기\n",
    "game_id = '20190423HTLG02019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'gameId': game_id,\n",
    "    'half': '1'\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/59.0.3071.115 Safari/537.36',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'Host': 'm.sports.naver.com',\n",
    "    'Referer': 'http://m.sports.naver.com/baseball/gamecenter/kbo/index.nhn?&gameId='\n",
    "               + game_id\n",
    "               + '&tab=relay'\n",
    "}\n",
    "\n",
    "response = requests.get(relay_url, params=params, headers=headers)\n",
    "\n",
    "txt = {}\n",
    "js = response.json()\n",
    "if isinstance(js, str):\n",
    "    js = json.loads(js)\n",
    "last_inning = js['currentInning']\n",
    "\n",
    "txt['relayList'] = {}\n",
    "\n",
    "for i in range(len(js['relayList'])):\n",
    "    txt['relayList'][js['relayList'][i]['no']] = js['relayList'][i]\n",
    "    texts = txt['relayList'][js['relayList'][i]['no']]['textOptionList']\n",
    "    for i in range(len(texts)):\n",
    "        texts[i]['text'].encode('cp949', 'ignore')\n",
    "txt['homeTeamLineUp'] = js['homeTeamLineUp']\n",
    "txt['awayTeamLineUp'] = js['awayTeamLineUp']\n",
    "\n",
    "txt['stadium'] = js['schedule']['stadium']\n",
    "\n",
    "response.close()\n",
    "\n",
    "for inn in range(2, last_inning + 1):\n",
    "    params = {\n",
    "        'gameId': game_id,\n",
    "        'half': str(inn)\n",
    "    }\n",
    "\n",
    "    response = requests.get(relay_url, params=params, headers=headers)\n",
    "    if response is not None:\n",
    "        js = response.json()\n",
    "        response.close()\n",
    "        if isinstance(js, str):\n",
    "            js = json.loads(js)\n",
    "\n",
    "        for i in range(len(js['relayList'])):\n",
    "            txt['relayList'][js['relayList'][i]['no']] = js['relayList'][i]\n",
    "            texts = txt['relayList'][js['relayList'][i]['no']]['textOptionList']\n",
    "            for i in range(len(texts)):\n",
    "                texts[i]['text'].encode('cp949', 'ignore')\n",
    "    response.close()\n",
    "\n",
    "params = {\n",
    "    'gameId': game_id\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, '\n",
    "                  'like Gecko) Chrome/59.0.3071.115 Safari/537.36',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'Host': 'm.sports.naver.com',\n",
    "    'Referer': 'http://m.sports.naver.com/baseball/gamecenter/kbo/index.nhn?gameId='\n",
    "               + game_id\n",
    "               + '&tab=record'\n",
    "}\n",
    "\n",
    "response = requests.get(record_url, params=params, headers=headers)\n",
    "\n",
    "p = regex.compile('(?<=\\\"etcRecords\\\":\\[)[\\\\\\.\\{\\}\\\"0-9:\\s\\(\\)\\,\\ba-z가-힣\\{\\}]+')\n",
    "result = p.findall(response.text)\n",
    "if len(result) == 0:\n",
    "    txt['referee'] = ''\n",
    "else:\n",
    "    txt['referee'] = result[0].split('{')[-1].split('\":\"')[1].split(' ')[0]\n",
    "    \n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# team lineup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모바일 아닌 PC 페이지에서 가져와야 한다.\n",
    "- 라인업 내용은 페이지 html에 하드코딩되어있지 않다.\n",
    "- jquery? 사용한 자바스크립트 형태(아마도) 스크립트로 경기 메타를 object로 저장하고 있다.\n",
    "- 이걸 불러와서 페이지에 뿌리는 식이다.\n",
    "- 그래서 다음 순서로 진행한다.\n",
    "    1. PC 페이지 html에서 BS4를 써서 `<script>` 있는 부분만 싹 긁어온다.\n",
    "    2. 원하는 object 코드가 있는 스크립트를 찾는다. (object를 define하는 코드 텍스트를 검색)\n",
    "    3. object 부분만 긁어온다. JSON 호환가능한 코드\n",
    "    4. JSON 객체로 바꾼다.\n",
    "    5. 라인업 부분만 가져온다.\n",
    "\n",
    "- 가져온 라인업 내용은 batting order 순서대로 나열되어있다.\n",
    "- key를 `'pos'`로 입력해서 포지션 내용만 가져올 수 있다.\n",
    "- 맨앞의 글자가 선발 당시 라인업이다.\n",
    "    - 도중 교체 출전은 '교', 지명타자는 '지'\n",
    "    - 1, 2, 3루수는 한자로 一, 二, 三\n",
    "    - 나머지는 포, 유, 좌, 중, 우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과 기록 페이지라서 게임단위 메타 데이터만 있다.\n",
    "- 선수 별로는 pCode 정도가 전부\n",
    "- 모바일 페이지에서 긁어온 것과 합쳐야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 버그있던 경기 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl = txt.get('awayTeamLineUp')\n",
    "abat = atl.get('batter')\n",
    "apit = atl.get('pitcher')\n",
    "hit_columns = ['name', 'pCode', 'posName', 'pos',\n",
    "               'hitType', 'seqno', 'batOrder',\n",
    "               'ab', 'hit', 'run', 'rbi',\n",
    "               'hr', 'bb', 'so']\n",
    "pit_columns = ['name', 'pCode', 'hitType', 'seqno',\n",
    "               'inn', 'run', 'er', 'hit', 'hr',\n",
    "               'bb', 'kk', 'hbp', 'wp', 'ballCount']\n",
    "bats = pd.DataFrame(abat, columns=hit_columns).sort_values(['batOrder', 'seqno'])\n",
    "pits = pd.DataFrame(apit, columns=pit_columns).sort_values('seqno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineup_url = 'https://sports.news.naver.com/gameCenter/gameRecord.nhn?category=kbo&gameId='\n",
    "lurl = lineup_url + '20190423HTLG02019'\n",
    "lreq = requests.get(lurl)\n",
    "lsoup = BeautifulSoup(lreq.text, 'lxml')\n",
    "lreq.close()\n",
    "\n",
    "scripts = lsoup.find_all('script')\n",
    "text = None\n",
    "\n",
    "for tag in scripts:\n",
    "    if len(tag.contents) > 0:\n",
    "        if tag.contents[0].find('DataClass = ') > 0:\n",
    "            contents = tag.contents[0]\n",
    "            start = contents.find('DataClass = ') + 36\n",
    "            end = contents.find('}}}') + 3\n",
    "            oldjs = contents[start:end]\n",
    "            contents = json.loads(oldjs)\n",
    "            break\n",
    "            \n",
    "bbs = contents.get('battersBoxscore')\n",
    "al = bbs.get('away')\n",
    "hl = bbs.get('home')\n",
    "\n",
    "pos_dict = {'중': '중견수', '좌': '좌익수', '우': '우익수', '유': '유격수', '포': '포수', '지': '지명타자',\n",
    "            '一': '1루수', '二': '2루수', '三': '3루수'}\n",
    "\n",
    "posnum_dict = {'중': 8, '좌': 7, '우': 9, '유': 6, '포': 2, '지': 0,\n",
    "            '一': 3, '二': 4, '三': 5}\n",
    "\n",
    "homes = []\n",
    "aways = []\n",
    "for i in range(len(hl)):\n",
    "    player = hl[i]\n",
    "    name = player.get('name')\n",
    "    pos = player.get('pos')[0]\n",
    "    homes.append({'name': name, 'pos': pos})\n",
    "\n",
    "for i in range(len(al)):\n",
    "    player = al[i]\n",
    "    name = player.get('name')\n",
    "    pos = player.get('pos')[0]\n",
    "    aways.append({'name': name, 'pos': pos})\n",
    "\n",
    "hit_columns = ['name', 'pCode', 'posName', 'pos',\n",
    "               'hitType', 'seqno', 'batOrder',\n",
    "               'ab', 'hit', 'run', 'rbi',\n",
    "               'hr', 'bb', 'so']\n",
    "pit_columns = ['name', 'pCode', 'hitType', 'seqno',\n",
    "               'inn', 'run', 'er', 'hit', 'hr',\n",
    "               'bb', 'kk', 'hbp', 'wp', 'ballCount']\n",
    "\n",
    "atl = txt.get('awayTeamLineUp')\n",
    "abat = atl.get('batter')\n",
    "apit = atl.get('pitcher')\n",
    "abats = pd.DataFrame(abat, columns=hit_columns).sort_values(['batOrder', 'seqno'])\n",
    "apits = pd.DataFrame(apit, columns=pit_columns).sort_values('seqno')\n",
    "\n",
    "htl = txt.get('homeTeamLineUp')\n",
    "hbat = htl.get('batter')\n",
    "hpit = htl.get('pitcher')\n",
    "hbats = pd.DataFrame(hbat, columns=hit_columns).sort_values(['batOrder', 'seqno'])\n",
    "hpits = pd.DataFrame(hpit, columns=pit_columns).sort_values('seqno')\n",
    "\n",
    "abats2 = abats.copy()\n",
    "hbats2 = hbats.copy()\n",
    "for a in aways:\n",
    "    if a.get('pos') == '교':\n",
    "        continue\n",
    "    abats2.loc[abats2.name == a.get('name'), 'posName'] = pos_dict.get(a.get('pos'))\n",
    "    abats2.loc[abats2.name == a.get('name'), 'pos'] = posnum_dict.get(a.get('pos'))\n",
    "for h in homes:\n",
    "    if h.get('pos') == '교':\n",
    "        continue\n",
    "    hbats2.loc[hbats2.name == h.get('name'), 'posName'] = pos_dict.get(a.get('pos'))\n",
    "    hbats2.loc[hbats2.name == h.get('name'), 'pos'] = posnum_dict.get(a.get('pos'))\n",
    "hbats2['homeaway'] = 'h'\n",
    "abats2['homeaway'] = 'a'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
